{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty dataframe to add the predictions and the country code - till when we have the ground truth data\n",
    "df_preds_all = pd.DataFrame(columns=['country_code','gpi_predicted'])\n",
    "l_countrypreds = [] #list to add the countries for which we have predictions\n",
    "count = 0\n",
    "for i in os.listdir('XGBoost_results/'):\n",
    "    if i.endswith('_xgb_predictions.csv'):\n",
    "        country = i.split('_')[0]\n",
    "        \n",
    "        if country !='WE' and country != 'SY':\n",
    "            \n",
    "            preds = pd.read_csv('XGBoost_results/'+ i , index_col = 0)\n",
    "            \n",
    "            ##add the new predictions\n",
    "            #newpreds = pd.read_csv('../../GPI_project/new_2021/XGBoost_results_2021/%s_xgb_predictions.csv' %country, index_col = 0)\n",
    "            \n",
    "            #preds = preds.append(newpreds)\n",
    "            \n",
    "            #Get the length of the predictions. It is enough to read one prediction file since all predictions' length is the same.\n",
    "            if count == 0:\n",
    "                length = len(preds)\n",
    "                count = count+1\n",
    "            df_preds = pd.DataFrame({'gpi_predicted':preds.prediction1}).reset_index(drop = True)\n",
    "            l_country_name = [country] * length \n",
    "            df_country = pd.DataFrame({'country_code':l_country_name})\n",
    "\n",
    "            #Merge the predictions dataframe with the corresponding country code in the form of dataframe\n",
    "            country_preds = pd.merge(df_preds, df_country, left_index=True, right_index=True)\n",
    "            df_preds_all = df_preds_all.append(country_preds, sort=False)\n",
    "\n",
    "            l_countrypreds.append(country)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index on the dataframe with all the predictions per country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds_all.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty dataframe to add the real GPI score, the monthyear and the country code\n",
    "df_interp_all = pd.DataFrame(columns=['country_code','MonthYear','GPI_score'])\n",
    "l_country_interp = [] #list to add the countries for which we have real gpi\n",
    "\n",
    "for i in os.listdir('data/interpolated_gpi/'):\n",
    "    if i.startswith(\"interpolated\"):\n",
    "        \n",
    "        #Get the country code\n",
    "        country = i.split('_')[-1].split('.')[0]\n",
    "        \n",
    "        if country !='WE' and country != 'SY' :\n",
    "            #Create a list with the country name to later append on the main dataframe\n",
    "            l_country_name = [country] * length\n",
    "            df_country = pd.DataFrame({'country_code':l_country_name})\n",
    "\n",
    "            #Read the file \n",
    "            file = pd.read_csv('data/interpolated_gpi/' + i , index_col = 0)\n",
    "            #Get the test set length of the file that correspond to the length of the predicted gpi\n",
    "            t_file = file.tail(length)\n",
    "            #Reset the index of the t_file\n",
    "            t_file = t_file.reset_index()\n",
    "\n",
    "            #Merge the real gpi with the country code in the form of a dataframe\n",
    "            country_interp = pd.merge(t_file, df_country, left_index=True, right_index=True)\n",
    "            df_interp_all = df_interp_all.append(country_interp, sort=False)\n",
    "\n",
    "            l_country_interp.append(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index on the dataframe with all the predictions per country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interp_all.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_interp_all), len(df_preds_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now group the two dataframes based on the country code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped1 = df_interp_all.groupby('country_code') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2 = df_preds_all.groupby('country_code') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the fips with the countries dataframe that will be used below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fips = pd.read_csv('data/Fips10_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fips.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the extra the forecast dates that will be used for the final dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var = pd.read_csv('data/all_variables_and_GPI_monthly_all_countries/all_variables_%s.csv'%country, index_col=0)\n",
    "all_var.index.to_list()\n",
    "\n",
    "f_date = 202104 #set the first forecast date\n",
    "l_date = 202110 #set last+1 forecast date (to get the last forecast)\n",
    "df = all_var.index.to_list().index(f_date)\n",
    "dl = all_var.index.to_list().index(l_date)\n",
    "f_dates = all_var.index.to_list()[df:dl]\n",
    "n_f = 6 #set the number of forecasts ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty dataframe that will be the final one to add the forecasts as well\n",
    "final = pd.DataFrame(columns=['country_code', 'MonthYear', 'GPI_score', 'gpi_predicted'])\n",
    "\n",
    "#For each country merge the dataframes above\n",
    "for country in l_country_interp: \n",
    "    df1 = grouped1.get_group(country).reset_index(drop=True)\n",
    "    df2 = grouped2.get_group(country).reset_index(drop=True).drop(['country_code'], axis=1)\n",
    "    df_both = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "    \n",
    "    #Prepare the dataframe with new forecast values\n",
    "    forecasts = pd.read_csv('XGBoost_forecasts/%s_xgb_predictions.csv' %country, index_col = 0)\n",
    "    forecasts = forecasts.iloc[:,:n_f+1]\n",
    "    \n",
    "    forecasts = forecasts.iloc[:,1:].T.reset_index(drop = True)\n",
    "    flength = len(forecasts)\n",
    "    forecasts.columns = ['gpi_predicted']\n",
    "    forecasts['MonthYear'] = f_dates\n",
    "    forecasts['country_code'] = flength * [country]  \n",
    "    \n",
    "    #Append the forecasts to the dataframe\n",
    "    df_both = df_both.append(forecasts)\n",
    "    df_both.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    #Create an extra column with the country corresponding to the fips code\n",
    "    country_fips = df_fips.at[df_fips['FIPS_10_4'].eq(country).idxmax(),'Country']\n",
    "    fips_country_name = [country_fips] * len(df_both)\n",
    "    df_country = pd.DataFrame({'country_name':fips_country_name})\n",
    "    \n",
    "    #Merge df_both with df_country\n",
    "    df_both_country = pd.merge(df_country, df_both, left_index=True, right_index=True)\n",
    "    \n",
    "    #Append on the final dataframe\n",
    "    final = final.append(df_both_country, sort=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been asked to add to the dataframe the variables importance. The following produces this information to add them to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_train_date = 202103 #set last training date, which corresponds to the last date of the ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty dataframe to add all important variables for all countries\n",
    "var_all = pd.DataFrame()\n",
    "#Create a dataframe with all important variables and the country code\n",
    "for i in os.listdir('XGBoost_results/'):\n",
    "    \n",
    "    if i.endswith('_xgb_impvar.csv'):\n",
    "        country = i.split('_')[0]\n",
    "        \n",
    "        if country !='WE' and country != 'SY':\n",
    "            var = pd.read_csv('XGBoost_results/'+ i , index_col = 0)\n",
    "            \n",
    "            #add the variable importance used for the forecast\n",
    "            newvar = pd.read_csv('XGBoost_forecasts/%s_xgb_impvar.csv' %country, index_col = 0)\n",
    "            newvar['MonthYear'] = [l_train_date] * len(newvar)\n",
    "                        \n",
    "            #Append the forecasted values as well\n",
    "            var = var.append(newvar)          \n",
    "            #Use pivot so that you have as column names the variables and rows their importance/value\n",
    "            var = var.pivot(index='MonthYear', columns='Variable', values='Importance')\n",
    "            #Add the country code to the dataframe\n",
    "            var['country_code'] = [country] * len(var)\n",
    "            \n",
    "            #Now, delete the MonthYear column. You can anyway merge with the final dataframe, since the importance is ordered by date\n",
    "            var.reset_index(inplace = True)\n",
    "            \n",
    "            #Get as MonthYear the date of the prediction and not the date of the last training\n",
    "            #Get any column of 'MonthYear' for the matching since it is the same\n",
    "            var['MonthYear'] = country_interp['MonthYear'].append(pd.Series(f_dates)).reset_index(drop=True)\n",
    "            \n",
    "            #Create the dataframe with the same forecast variables \n",
    "            var2 = pd.concat([pd.DataFrame(var.iloc[-1]).T.iloc[:,1:]] * (len(f_dates[1:])))\n",
    "            var2.reset_index(drop = True, inplace = True)\n",
    "            var2['MonthYear'] = f_dates[1:]\n",
    "            \n",
    "            #Append to the biggere dataframe\n",
    "            var = var.append(var2)\n",
    "            \n",
    "            #Merge the country dataframe of variables importance with the dataframe that contains all country var imp\n",
    "            var_all = var_all.append(var, sort=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final), len(var_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, merge the variable importance information with the final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final = pd.merge(final, var_all, on=['country_code','MonthYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganise the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = final.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = columns[1:2] + columns[4:5] + columns[0:1] + columns[2:4] + columns[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final.country_code.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round the numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.iloc[:,3:] = round(final.iloc[:,3:],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the prefix from the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_new = final.iloc[:,5:].columns.str.lstrip('event_count_').to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the columns with numbers from strings to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_new = [int(x) for x in col_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new column names to replace the old:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_new2 = final.columns.to_list()[:5] + col_new "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the old column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns = col_new2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the columns with the event numbers in ascending order so that we can merge and match easily the descriptive titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_new3 = final.columns[:5].to_list() + final.columns[5:].sort_values().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[col_new3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add the descriptive names to the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_variables = pd.read_csv('data/description_variables.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the column names that should be made descriptive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_change = final.columns[5:].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the columns so that you can easily merge to match the descriptive names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_change.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_change = pd.DataFrame(columns_change, columns= ['CAMEOEVENTCODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_variables = name_variables.sort_values('CAMEOEVENTCODE').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_changed = pd.merge(columns_change, name_variables, on=\"CAMEOEVENTCODE\")['EVENTDESCRIPTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_changed = columns_changed.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = final.columns.to_list()[:5] + columns_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns = final_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('data/all_countries_for_dashboard.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
