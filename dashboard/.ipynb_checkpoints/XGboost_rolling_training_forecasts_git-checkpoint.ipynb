{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use XGboost for machine learning. XGboost is not an Sklearn library, but you can combine XGboost with Sklearn to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our search space for grid search\n",
    "random_grid = {\n",
    "    'objective' : ['reg:squarederror'],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': range(3, 10),\n",
    "    'colsample_bytree': [i/10.0 for i in range(1, 3)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition functions: if we variables which have more than 60% zeros delete them\n",
    "def non_zero_variables(df):\n",
    "    cols = df.columns\n",
    "    cols_non_0 = []\n",
    "    for col in cols:\n",
    "        if ((df[col].eq(0).sum(axis=0)) < 0.4 * (len(df[col]))): #if we have more than 60% zeros\n",
    "            cols_non_0.append(col)\n",
    "    return cols_non_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models and predict 1-month-ahead GPI values till the date we have the last official GPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the last date of the official GPI:\n",
    "lastoffic = 202103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the last date to forecast the GPI (you can predict up to 6-months-ahead from the last ground-truth data):\n",
    "lasttrain = 202003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for predictions when new ground truth data is available\n",
    "train_set = 0.5\n",
    "\n",
    "path = 'data/all_variables_and_GPI_monthly_all_countries/'\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    \n",
    "    if i != '.DS_Store': \n",
    "        \n",
    "        country = i.split('_')[-1].split('.')[0]\n",
    "         \n",
    "        if country != 'WE':\n",
    "            \n",
    "            print(country)\n",
    "        \n",
    "            all_var = pd.read_csv(path + 'all_variables_%s.csv'%country, index_col=0)\n",
    "            \n",
    "            #Delete all columns that have more than 60% of their values 0\n",
    "            variables_non_0 = non_zero_variables(all_var) #Filter the variables that have many zeros\n",
    "            df_country = all_var[variables_non_0]\n",
    "            \n",
    "            df_country = df_country.loc[df_country.index <= lastoffic]\n",
    "\n",
    "            #Set the target variable\n",
    "            Y = df_country['GPI']\n",
    "\n",
    "            #Set the independent variables\n",
    "            X = df_country.loc[:, df_country.columns != 'GPI']\n",
    "            \n",
    "            #Set the training sets:\n",
    "            Y_train = Y.loc[Y.index <= lasttrain]\n",
    "            Y_train = Y_train[int(Y_train.shape[0]*train_set):]\n",
    "            X_train = X.loc[Y.index <= lasttrain]\n",
    "            X_train = X_train[int(X_train.shape[0]*train_set):]\n",
    "            \n",
    "            #Set the test sets\n",
    "            Y_test = Y.loc[Y.index > lasttrain]\n",
    "            X_test = X.loc[X.index > lasttrain]\n",
    "            \n",
    "            ###Rolling Training:\n",
    "\n",
    "            #Create a dataframe to add the predictions\n",
    "            Predictions = pd.DataFrame(columns = ['MonthYear','prediction1'])#we keep the monthyear of the last trainining data\n",
    "\n",
    "            #Create an empty dataframe for the variables\n",
    "            all_importances =  pd.DataFrame(columns = ['Variable', 'Importance','MonthYear'])\n",
    "\n",
    "            k = 0\n",
    "\n",
    "            for i in range(0, len(X_test)): #We have to do 73 trainings\n",
    "\n",
    "                print(i)#print the cycle\n",
    "\n",
    "                tscv = TimeSeriesSplit(n_splits=10).split(X_train)\n",
    "\n",
    "                l_predictions = []\n",
    "\n",
    "               #Train the model\n",
    "\n",
    "                xg_reg = xgb.XGBRegressor() #model to tune #\n",
    "                                            \n",
    "                xg_reg_random = GridSearchCV(estimator = xg_reg, param_grid = random_grid,\n",
    "                                                cv = tscv,  n_jobs = -1)\n",
    "\n",
    "                #Best model\n",
    "                model = xg_reg_random.fit(X_train, Y_train)\n",
    "\n",
    "                #If we have less than 1 data points ahead to predict, then increase the value of the k variable\n",
    "                if (len(X_test) - i) < 1: \n",
    "                    k = k + 1 \n",
    "                    #print('k:',k)\n",
    "\n",
    "                #Make the prediction(s)\n",
    "                for j in range(i, i+1-k):\n",
    "                    Y_pred = model.predict(X_test.iloc[[j]])\n",
    "                    l_predictions.append(Y_pred[0])\n",
    "\n",
    "                #k variable helps me understand how many months ahead I can predict\n",
    "                if k>0:\n",
    "                    l_predictions2 = []\n",
    "                    for l in range(0, k):\n",
    "                        l_predictions2.append('-')\n",
    "                    #Concatenate the predictions list and the '-' list to add them on the dataframe\n",
    "                    l_predictions = l_predictions + l_predictions2\n",
    "                \n",
    "                #Concatenate the month and Year of the last training with the prediction list to add them on the dataframe\n",
    "                l_predictions = [str(X_train.index[-1])] + l_predictions\n",
    "\n",
    "                #Add monthyear and predictions on the dataframe\n",
    "                Predictions_length = len(Predictions)\n",
    "                Predictions.loc[Predictions_length] = l_predictions\n",
    "\n",
    "                #Variables importance\n",
    "                importances = model.best_estimator_.feature_importances_ #get the variables importance\n",
    "\n",
    "                #Match the values with the names of the variables\n",
    "                dict_variables = {}\n",
    "                for feat, importance in zip(X_train, importances):\n",
    "                    dict_variables[feat] = importance\n",
    "\n",
    "                df_importances = pd.DataFrame(dict_variables.items(), columns=['Variable', 'Importance'])\n",
    "\n",
    "                df_importances['MonthYear'] = str(X_train.index[-1])#get the last month of the training\n",
    "\n",
    "                all_importances = all_importances.append(df_importances).reset_index(drop = True) #add to the total df for importance\n",
    "                \n",
    "                #Set the new training sets\n",
    "                X_train = X_train.iloc[1:]\n",
    "                X_train = X_train.append(X_test.iloc[i])\n",
    "                Y_train = Y_train[1:]\n",
    "                Y_train = Y_train.append(Y_test.iloc[[i]])\n",
    "                \n",
    "                \n",
    "            #Save the predictions appending to the old dataframe\n",
    "            Predictions.to_csv('XGBoost_results/%s_xgb_predictions.csv' %country, mode='a', index=True, header=False)  \n",
    "\n",
    "            #Save the importances appending to the old dataframe\n",
    "            all_importances.to_csv('XGBoost_results/%s_xgb_impvar.csv' %country, mode='a', index=True, header=False)  \n",
    "\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(\"Time ended - country %s =\" %country, current_time)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasts: After the last official gund truth data you can predict GPI 6-months-ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the months ahead you want to predict after the last ground truth values.\n",
    "preds_ahead = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be used for creating the predictions dataframe\n",
    "col_list = ['prediction' + str(x) for x in range(1, preds_ahead + 1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for forecasts\n",
    "\n",
    "path = 'data/all_variables_and_GPI_monthly_all_countries/'\n",
    "\n",
    "train_set = 0.5\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    \n",
    "    if i != '.DS_Store':\n",
    "        \n",
    "        country = i.split('_')[-1].split('.')[0]\n",
    "         \n",
    "        print(country)\n",
    "        \n",
    "        if country != 'WE':\n",
    "\n",
    "            all_var = pd.read_csv(path + 'all_variables_%s.csv'%country, index_col=0)\n",
    "\n",
    "            #Delete all columns that have more than 60% of their values 0\n",
    "            variables_non_0 = non_zero_variables(all_var) #Filter the variables that have many zeros\n",
    "            df_country = all_var[variables_non_0]\n",
    "\n",
    "            #Divide the data for training and for prediction\n",
    "            df_country_training = df_country.loc[df_country.index <= lastoffic]\n",
    "            df_country_future = df_country.loc[df_country.index > lastoffic]\n",
    "\n",
    "            #Set the target variable\n",
    "            Y = df_country_training['GPI']\n",
    "\n",
    "            #Set the independent variables\n",
    "            X = df_country_training.loc[:, df_country_training.columns != 'GPI']\n",
    "\n",
    "            #Set the training sets:\n",
    "            Y_train = Y[int(Y.shape[0]*train_set):]\n",
    "            X_train = X[int(X.shape[0]*train_set):]\n",
    "\n",
    "\n",
    "            #Set the data for future prediction\n",
    "            X_future = df_country_future.loc[:, df_country_future.columns != 'GPI']\n",
    "\n",
    "            ### Rolling Training:\n",
    "\n",
    "            #Create a dataframe to add the predictions\n",
    "            Predictions = pd.DataFrame(columns = ['MonthYear'] + col_list) #create the lenght based on the months to predict\n",
    "            \n",
    "            #Create an empty dataframe for the variables\n",
    "            all_importances =  pd.DataFrame(columns = ['Variable', 'Importance','MonthYear'])\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=10).split(X_train)\n",
    "\n",
    "            l_predictions = []\n",
    "\n",
    "            #Train the model\n",
    "\n",
    "            xg_reg = xgb.XGBRegressor() #model to tune #\n",
    "                                            #the default type of importance is gain, i.e. (importance_type='gain')\n",
    "                                               #n_iter = 20, cv = tscv,  n_jobs = -1)\n",
    "\n",
    "            xg_reg_random = GridSearchCV(estimator = xg_reg, param_grid = random_grid,\n",
    "                                                cv = tscv,  n_jobs = -1)\n",
    "\n",
    "            #Best model\n",
    "            model = xg_reg_random.fit(X_train, Y_train)\n",
    "\n",
    "            #Make the prediction(s)\n",
    "            for j in range(0, preds_ahead): #months-ahead to predict\n",
    "                Y_pred = model.predict(X_future.iloc[[j]])\n",
    "                l_predictions.append(Y_pred[0])\n",
    "\n",
    "            #Concatenate the month and Year of the last training with the prediction list to add them on the dataframe\n",
    "            l_predictions = [str(X_train.index[-1])] + l_predictions\n",
    "\n",
    "            #Add monthyear and predictions on the dataframe\n",
    "            Predictions_length = len(Predictions)\n",
    "            Predictions.loc[Predictions_length] = l_predictions\n",
    "\n",
    "            #Variables importance\n",
    "            importances = model.best_estimator_.feature_importances_ #get the variables importance\n",
    "\n",
    "            #Match the values with the names of the variables\n",
    "            dict_variables = {}\n",
    "            for feat, importance in zip(X_train, importances):\n",
    "                dict_variables[feat] = importance\n",
    "\n",
    "            df_importances = pd.DataFrame(dict_variables.items(), columns=['Variable', 'Importance'])\n",
    "\n",
    "            #Save the predictions\n",
    "            Predictions.to_csv('XGBoost_forecasts/%s_xgb_predictions.csv' %country)\n",
    "\n",
    "            #Save the importances\n",
    "            df_importances.to_csv('XGBoost_forecasts/%s_xgb_impvar.csv' %country)\n",
    "\n",
    "            #Save the model hyperparameters\n",
    "\n",
    "            #Print the time the iteration ended\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(\"Time ended - country %s =\" %country, current_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
